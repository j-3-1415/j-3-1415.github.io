---
layout: single
author_profile: false
---

<head>
	<title>TVGL | My Website</title>
	<meta charset="utf-8" />
	<link rel="stylesheet" href="/assets/css/main.css" />
</head>

<body>
	<header>
	<h1>TVGL</h1>
		<p><small>Project Dates: 
			<em>January 2021 - March 2021</em></small>
		</p>
		<a href="/assets/ProjectFiles/TVGL.pdf" rel="nofollow noopener noreferrer me"><img src="/assets/pdf_icon.jpg" width="30px"><span class="label"></span></a>
		<a href="https://github.com/aboomer07/HighDimensional_TVGL" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label"></span></a>
	</header>
	<main>
		<article>
			This project was done in collaboration with Andrew Boomer during my masters program at the Toulouse School of Economics.
			<h2>Project Overview</h2>
			<p>
				This presentation was the final project for my High Dimensional Models class at the Toulouse School of Economics. It is an introduction to gaussian graphical models, inducing network sparsity via regularization, and the alternating direction method of multipliers (ADMM) optimization method. It continues with a replication and senstitivty analysis extension of the paper "Network Inference via the Time-Varying Graphical Lasso" by David Hallac, which can be found <a href="https://cs.stanford.edu/people/jure/pubs/tvgl-kdd17.pdf">here</a>. The paper adds a regularization function to penalize change in the network structure over time, which allows for identifying various transitions and breaks in network structure. We extended their analysis by looking at an extended time period and an expanded set of stocks to test the robustness of their method.

			</p>
			<h2>Data Sources</h2>
			<p>
				We replicated the authors application to a panel of stock price data.
			</p>
			<h2>Tools Used</h2>
			<p>
				The slides were built using beamer in Latex. The project was coded in python, and used the Pandas, Numpy, Networkx, Sklearn, and Seaborn libraries.
			</p>
		</article>
	</main>
</body>